
model_name_or_path: "Qwen/Qwen2.5-3B-Instruct"
dataset_path: "./data/qwen2.5_dpo_dataset"
output_dir: "./qwen2.5-3b-dpo-output"


beta: 0.1                          
max_length: 1024                   
max_prompt_length: 512           


lora_r: 32                          
lora_alpha: 64
lora_dropout: 0.05
target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"] 

learning_rate: 5.0e-6              
lr_scheduler_type: "cosine"
warmup_ratio: 0.1
per_device_train_batch_size: 1  
per_device_eval_batch_size: 1    
gradient_accumulation_steps: 8     



num_train_epochs: 1            
logging_steps: 10
save_steps: 500                  
eval_steps: 200                     
evaluation_strategy: "steps"
bf16: true                        
report_to: "wandb"                 